{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 7 - Session 2 - example 3\n",
    "\n",
    "Predict house prices\n",
    "\n",
    "packages used: pandas, scikit-learn, openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>age</th>\n",
       "      <th>distance_MRT</th>\n",
       "      <th>stores</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012.916667</td>\n",
       "      <td>32.0</td>\n",
       "      <td>84.87882</td>\n",
       "      <td>10</td>\n",
       "      <td>24.98298</td>\n",
       "      <td>121.54024</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012.916667</td>\n",
       "      <td>19.5</td>\n",
       "      <td>306.59470</td>\n",
       "      <td>9</td>\n",
       "      <td>24.98034</td>\n",
       "      <td>121.53951</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013.583333</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013.500000</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>390.56840</td>\n",
       "      <td>5</td>\n",
       "      <td>24.97937</td>\n",
       "      <td>121.54245</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4082.01500</td>\n",
       "      <td>0</td>\n",
       "      <td>24.94155</td>\n",
       "      <td>121.50381</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2012.666667</td>\n",
       "      <td>5.6</td>\n",
       "      <td>90.45606</td>\n",
       "      <td>9</td>\n",
       "      <td>24.97433</td>\n",
       "      <td>121.54310</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>2013.250000</td>\n",
       "      <td>18.8</td>\n",
       "      <td>390.96960</td>\n",
       "      <td>7</td>\n",
       "      <td>24.97923</td>\n",
       "      <td>121.53986</td>\n",
       "      <td>40.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>8.1</td>\n",
       "      <td>104.81010</td>\n",
       "      <td>5</td>\n",
       "      <td>24.96674</td>\n",
       "      <td>121.54067</td>\n",
       "      <td>52.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>2013.500000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>90.45606</td>\n",
       "      <td>9</td>\n",
       "      <td>24.97433</td>\n",
       "      <td>121.54310</td>\n",
       "      <td>63.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     transaction_date   age  distance_MRT  stores       lat        lon  price\n",
       "0         2012.916667  32.0      84.87882      10  24.98298  121.54024   37.9\n",
       "1         2012.916667  19.5     306.59470       9  24.98034  121.53951   42.2\n",
       "2         2013.583333  13.3     561.98450       5  24.98746  121.54391   47.3\n",
       "3         2013.500000  13.3     561.98450       5  24.98746  121.54391   54.8\n",
       "4         2012.833333   5.0     390.56840       5  24.97937  121.54245   43.1\n",
       "..                ...   ...           ...     ...       ...        ...    ...\n",
       "409       2013.000000  13.7    4082.01500       0  24.94155  121.50381   15.4\n",
       "410       2012.666667   5.6      90.45606       9  24.97433  121.54310   50.0\n",
       "411       2013.250000  18.8     390.96960       7  24.97923  121.53986   40.6\n",
       "412       2013.000000   8.1     104.81010       5  24.96674  121.54067   52.5\n",
       "413       2013.500000   6.5      90.45606       9  24.97433  121.54310   63.9\n",
       "\n",
       "[414 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from excel file and rename columns\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"../data/Real estate valuation data set.xlsx\")\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"X1 transaction date\": \"transaction_date\",\n",
    "        \"X5 latitude\": \"lat\",\n",
    "        \"X6 longitude\": \"lon\",\n",
    "        \"X2 house age\": \"age\",\n",
    "        \"X3 distance to the nearest MRT station\": \"distance_MRT\",\n",
    "        \"X4 number of convenience stores\": \"stores\",\n",
    "        \"Y house price of unit area\": \"price\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression \n",
    "\n",
    "1. Specify features and target variable\n",
    "2. Split train/test\n",
    "3. Apply sklearn.linear_model.LinearRegression\n",
    "4. Draw predicted values vs test values\n",
    "5. Compute 4 evaluation metrics ($R^2$, MSE, RMSE, MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414, 6) (414,)\n"
     ]
    }
   ],
   "source": [
    "# 1. Specify features and target variable\n",
    "\n",
    "X = df.iloc[:, 0:-1]\n",
    "y = df[\"price\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(289, 6) (289,) (125, 6) (125,)\n"
     ]
    }
   ],
   "source": [
    "# 2. Split train/test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.85014746e+00 -2.42551464e-01 -5.13870668e-03  1.07453372e+00\n",
      "  2.39100477e+02 -5.22365968e+01] -11355.385619716399\n",
      "Score (train) =  0.5862205607346797\n",
      "Score (test) =  0.5600810475775264\n"
     ]
    }
   ],
   "source": [
    "# 3. Apply linear regression, compute scores over train data and test data\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# linear regression over training data\n",
    "rgr = LinearRegression()\n",
    "rgr.fit(X_train, y_train)\n",
    "print(rgr.coef_, rgr.intercept_)\n",
    "print(\"Score (train) = \", rgr.score(X_train, y_train))\n",
    "print(\"Score (test) = \", rgr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Draw predicted values vs test values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# compute predicted values for test data\n",
    "y_pred = rgr.predict(X_test)\n",
    "\n",
    "# check graphically how well the predictions match actual values\n",
    "plt.scatter(y_pred, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2=0.5600810475775264, mae=6.184744566032061\n",
      "mse=73.56549791983365, rmse=8.577033165368643\n"
     ]
    }
   ],
   "source": [
    "# 5. Compute 4 evaluation metrics (R^2, MSE, RMSE, MAE)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"{r2=}, {mae=}\")\n",
    "print(f\"{mse=}, {rmse=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage of sklearn.dummy.DummyRegressor as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (train) =  0.0\n",
      "r2=-0.013981455468037751, mae=10.73676401384083\n",
      "mse=169.56316667472848, rmse=13.021642241849854\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "# dummy regression over training data\n",
    "rgr = DummyRegressor(strategy=\"mean\")\n",
    "rgr.fit(X_train, y_train)\n",
    "print(\"Score (train) = \", rgr.score(X_train, y_train))\n",
    "\n",
    "# compute predicted values for test data \n",
    "y_pred = rgr.predict(X_test)\n",
    "\n",
    "# check graphically how well the predictions match actual values\n",
    "plt.scatter(y_pred, y_test)\n",
    "\n",
    "# compute metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"{r2=}, {mae=}\")\n",
    "print(f\"{mse=}, {rmse=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate sklearn.linear_model.LinearRegression using cross validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052999</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.711797</td>\n",
       "      <td>-5.453073</td>\n",
       "      <td>-49.892841</td>\n",
       "      <td>-7.063486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.519385</td>\n",
       "      <td>-6.916183</td>\n",
       "      <td>-89.032691</td>\n",
       "      <td>-9.435714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.661823</td>\n",
       "      <td>-5.257454</td>\n",
       "      <td>-57.869860</td>\n",
       "      <td>-7.607224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.439505</td>\n",
       "      <td>-7.348360</td>\n",
       "      <td>-134.817953</td>\n",
       "      <td>-11.611113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.593270</td>\n",
       "      <td>-5.889224</td>\n",
       "      <td>-60.048366</td>\n",
       "      <td>-7.749088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_r2  test_neg_mean_absolute_error  \\\n",
       "0  0.052999    0.003001  0.711797                     -5.453073   \n",
       "1  0.003000    0.003001  0.519385                     -6.916183   \n",
       "2  0.002998    0.002001  0.661823                     -5.257454   \n",
       "3  0.004998    0.003000  0.439505                     -7.348360   \n",
       "4  0.004002    0.002001  0.593270                     -5.889224   \n",
       "\n",
       "   test_neg_mean_squared_error  test_neg_root_mean_squared_error  \n",
       "0                   -49.892841                         -7.063486  \n",
       "1                   -89.032691                         -9.435714  \n",
       "2                   -57.869860                         -7.607224  \n",
       "3                  -134.817953                        -11.611113  \n",
       "4                   -60.048366                         -7.749088  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# cross validation with k=5 folds using linear regression\n",
    "cv_results = cross_validate(\n",
    "    LinearRegression(),\n",
    "    X,\n",
    "    y,\n",
    "    cv=5,\n",
    "    scoring=[\n",
    "        \"r2\",\n",
    "        \"neg_mean_absolute_error\",\n",
    "        \"neg_mean_squared_error\",\n",
    "        \"neg_root_mean_squared_error\",\n",
    "    ],\n",
    ")\n",
    "df = pd.DataFrame(cv_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean R-squared 0.5851559288125723\n",
      "Mean MAE 6.172859085203855\n",
      "Mean MSE 78.33234207633008\n",
      "Mean RMSE 8.85055603204285\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean R-squared\", df['test_r2'].mean())\n",
    "print(\"Mean MAE\", -df['test_neg_mean_absolute_error'].mean())\n",
    "print(\"Mean MSE\", -df['test_neg_mean_squared_error'].mean())\n",
    "print(\"Mean RMSE\", np.sqrt(-df['test_neg_mean_squared_error'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net (hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_l1_ratio</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002800</td>\n",
       "      <td>7.499348e-04</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.1, 'max_iter': 10...</td>\n",
       "      <td>0.666309</td>\n",
       "      <td>0.507689</td>\n",
       "      <td>0.626724</td>\n",
       "      <td>0.399908</td>\n",
       "      <td>0.587619</td>\n",
       "      <td>0.557650</td>\n",
       "      <td>0.094715</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001601</td>\n",
       "      <td>8.011342e-04</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.325</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.325, 'max_iter': ...</td>\n",
       "      <td>0.667551</td>\n",
       "      <td>0.506892</td>\n",
       "      <td>0.626705</td>\n",
       "      <td>0.400742</td>\n",
       "      <td>0.588331</td>\n",
       "      <td>0.558044</td>\n",
       "      <td>0.094851</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003001</td>\n",
       "      <td>6.332402e-04</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.55, 'max_iter': 1...</td>\n",
       "      <td>0.669260</td>\n",
       "      <td>0.505688</td>\n",
       "      <td>0.626617</td>\n",
       "      <td>0.401880</td>\n",
       "      <td>0.589220</td>\n",
       "      <td>0.558533</td>\n",
       "      <td>0.095048</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.549237e-03</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.775</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.775, 'max_iter': ...</td>\n",
       "      <td>0.671644</td>\n",
       "      <td>0.503619</td>\n",
       "      <td>0.626260</td>\n",
       "      <td>0.403446</td>\n",
       "      <td>0.590253</td>\n",
       "      <td>0.559045</td>\n",
       "      <td>0.095345</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002800</td>\n",
       "      <td>4.008070e-04</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 1.0, 'max_iter': 10...</td>\n",
       "      <td>0.675179</td>\n",
       "      <td>0.499566</td>\n",
       "      <td>0.625179</td>\n",
       "      <td>0.405727</td>\n",
       "      <td>0.591268</td>\n",
       "      <td>0.559384</td>\n",
       "      <td>0.095857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002799</td>\n",
       "      <td>7.490684e-04</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.3, 'l1_ratio': 0.1, 'max_iter': 10...</td>\n",
       "      <td>0.656540</td>\n",
       "      <td>0.510346</td>\n",
       "      <td>0.623985</td>\n",
       "      <td>0.393902</td>\n",
       "      <td>0.582869</td>\n",
       "      <td>0.553529</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002200</td>\n",
       "      <td>7.481121e-04</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.325</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.3, 'l1_ratio': 0.325, 'max_iter': ...</td>\n",
       "      <td>0.656440</td>\n",
       "      <td>0.510236</td>\n",
       "      <td>0.624154</td>\n",
       "      <td>0.393951</td>\n",
       "      <td>0.583148</td>\n",
       "      <td>0.553586</td>\n",
       "      <td>0.093590</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001799</td>\n",
       "      <td>3.998291e-04</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.3, 'l1_ratio': 0.55, 'max_iter': 1...</td>\n",
       "      <td>0.656291</td>\n",
       "      <td>0.510051</td>\n",
       "      <td>0.624387</td>\n",
       "      <td>0.394027</td>\n",
       "      <td>0.583580</td>\n",
       "      <td>0.553667</td>\n",
       "      <td>0.093611</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>9.488940e-07</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.775</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.3, 'l1_ratio': 0.775, 'max_iter': ...</td>\n",
       "      <td>0.656020</td>\n",
       "      <td>0.509632</td>\n",
       "      <td>0.624743</td>\n",
       "      <td>0.394168</td>\n",
       "      <td>0.584367</td>\n",
       "      <td>0.553786</td>\n",
       "      <td>0.093648</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>8.944696e-04</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.3, 'l1_ratio': 1.0, 'max_iter': 10...</td>\n",
       "      <td>0.655297</td>\n",
       "      <td>0.507917</td>\n",
       "      <td>0.625298</td>\n",
       "      <td>0.394538</td>\n",
       "      <td>0.586316</td>\n",
       "      <td>0.553873</td>\n",
       "      <td>0.093745</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001800</td>\n",
       "      <td>4.002338e-04</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.5, 'l1_ratio': 0.1, 'max_iter': 10...</td>\n",
       "      <td>0.652826</td>\n",
       "      <td>0.510875</td>\n",
       "      <td>0.621630</td>\n",
       "      <td>0.391732</td>\n",
       "      <td>0.581195</td>\n",
       "      <td>0.551652</td>\n",
       "      <td>0.092998</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002200</td>\n",
       "      <td>3.992085e-04</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.325</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.5, 'l1_ratio': 0.325, 'max_iter': ...</td>\n",
       "      <td>0.651794</td>\n",
       "      <td>0.510835</td>\n",
       "      <td>0.621616</td>\n",
       "      <td>0.391213</td>\n",
       "      <td>0.580934</td>\n",
       "      <td>0.551278</td>\n",
       "      <td>0.092938</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002001</td>\n",
       "      <td>1.237941e-06</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.5, 'l1_ratio': 0.55, 'max_iter': 1...</td>\n",
       "      <td>0.649989</td>\n",
       "      <td>0.510792</td>\n",
       "      <td>0.621562</td>\n",
       "      <td>0.390288</td>\n",
       "      <td>0.580413</td>\n",
       "      <td>0.550609</td>\n",
       "      <td>0.092830</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>8.945235e-04</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.775</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.5, 'l1_ratio': 0.775, 'max_iter': ...</td>\n",
       "      <td>0.647124</td>\n",
       "      <td>0.510746</td>\n",
       "      <td>0.621382</td>\n",
       "      <td>0.388214</td>\n",
       "      <td>0.579151</td>\n",
       "      <td>0.549324</td>\n",
       "      <td>0.092835</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002200</td>\n",
       "      <td>3.988753e-04</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.5, 'l1_ratio': 1.0, 'max_iter': 10...</td>\n",
       "      <td>0.647085</td>\n",
       "      <td>0.510687</td>\n",
       "      <td>0.620481</td>\n",
       "      <td>0.388018</td>\n",
       "      <td>0.577006</td>\n",
       "      <td>0.548655</td>\n",
       "      <td>0.092625</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010199</td>\n",
       "      <td>1.490421e-02</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.7, 'l1_ratio': 0.1, 'max_iter': 10...</td>\n",
       "      <td>0.650658</td>\n",
       "      <td>0.511118</td>\n",
       "      <td>0.619597</td>\n",
       "      <td>0.390521</td>\n",
       "      <td>0.580403</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.092568</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003801</td>\n",
       "      <td>2.227022e-03</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.325</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.7, 'l1_ratio': 0.325, 'max_iter': ...</td>\n",
       "      <td>0.649046</td>\n",
       "      <td>0.511064</td>\n",
       "      <td>0.619402</td>\n",
       "      <td>0.389654</td>\n",
       "      <td>0.579798</td>\n",
       "      <td>0.549793</td>\n",
       "      <td>0.092457</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001801</td>\n",
       "      <td>7.494116e-04</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.7, 'l1_ratio': 0.55, 'max_iter': 1...</td>\n",
       "      <td>0.646575</td>\n",
       "      <td>0.510977</td>\n",
       "      <td>0.619017</td>\n",
       "      <td>0.388044</td>\n",
       "      <td>0.578553</td>\n",
       "      <td>0.548634</td>\n",
       "      <td>0.092356</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002200</td>\n",
       "      <td>7.488537e-04</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.775</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.7, 'l1_ratio': 0.775, 'max_iter': ...</td>\n",
       "      <td>0.646511</td>\n",
       "      <td>0.510740</td>\n",
       "      <td>0.618217</td>\n",
       "      <td>0.387901</td>\n",
       "      <td>0.577522</td>\n",
       "      <td>0.548178</td>\n",
       "      <td>0.092224</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>6.345962e-04</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.7, 'l1_ratio': 1.0, 'max_iter': 10...</td>\n",
       "      <td>0.646448</td>\n",
       "      <td>0.510642</td>\n",
       "      <td>0.618249</td>\n",
       "      <td>0.387922</td>\n",
       "      <td>0.577626</td>\n",
       "      <td>0.548177</td>\n",
       "      <td>0.092223</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002799</td>\n",
       "      <td>1.165591e-03</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.9, 'l1_ratio': 0.1, 'max_iter': 10...</td>\n",
       "      <td>0.649099</td>\n",
       "      <td>0.511244</td>\n",
       "      <td>0.617733</td>\n",
       "      <td>0.389666</td>\n",
       "      <td>0.579922</td>\n",
       "      <td>0.549533</td>\n",
       "      <td>0.092208</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002000</td>\n",
       "      <td>6.327879e-04</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.325</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.9, 'l1_ratio': 0.325, 'max_iter': ...</td>\n",
       "      <td>0.647087</td>\n",
       "      <td>0.511168</td>\n",
       "      <td>0.617373</td>\n",
       "      <td>0.388568</td>\n",
       "      <td>0.579099</td>\n",
       "      <td>0.548659</td>\n",
       "      <td>0.092056</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.002599</td>\n",
       "      <td>8.010870e-04</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.9, 'l1_ratio': 0.55, 'max_iter': 1...</td>\n",
       "      <td>0.645932</td>\n",
       "      <td>0.511007</td>\n",
       "      <td>0.616681</td>\n",
       "      <td>0.387689</td>\n",
       "      <td>0.577792</td>\n",
       "      <td>0.547820</td>\n",
       "      <td>0.091939</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.002001</td>\n",
       "      <td>6.333917e-04</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.775</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.9, 'l1_ratio': 0.775, 'max_iter': ...</td>\n",
       "      <td>0.645834</td>\n",
       "      <td>0.510876</td>\n",
       "      <td>0.616524</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.577966</td>\n",
       "      <td>0.547783</td>\n",
       "      <td>0.091906</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001799</td>\n",
       "      <td>4.002581e-04</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'alpha': 0.9, 'l1_ratio': 1.0, 'max_iter': 10...</td>\n",
       "      <td>0.645736</td>\n",
       "      <td>0.510825</td>\n",
       "      <td>0.616506</td>\n",
       "      <td>0.387742</td>\n",
       "      <td>0.578131</td>\n",
       "      <td>0.547788</td>\n",
       "      <td>0.091889</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.002800  7.499348e-04         0.001400        0.000490         0.1   \n",
       "1        0.001601  8.011342e-04         0.001200        0.000401         0.1   \n",
       "2        0.003001  6.332402e-04         0.004999        0.006001         0.1   \n",
       "3        0.003000  1.549237e-03         0.002000        0.000632         0.1   \n",
       "4        0.002800  4.008070e-04         0.002201        0.000400         0.1   \n",
       "5        0.002799  7.490684e-04         0.001800        0.000748         0.3   \n",
       "6        0.002200  7.481121e-04         0.001800        0.000749         0.3   \n",
       "7        0.001799  3.998291e-04         0.001400        0.000799         0.3   \n",
       "8        0.002000  9.488940e-07         0.001600        0.000490         0.3   \n",
       "9        0.002000  8.944696e-04         0.001200        0.000400         0.3   \n",
       "10       0.001800  4.002338e-04         0.001200        0.000399         0.5   \n",
       "11       0.002200  3.992085e-04         0.001400        0.000490         0.5   \n",
       "12       0.002001  1.237941e-06         0.001199        0.000747         0.5   \n",
       "13       0.001999  8.945235e-04         0.001401        0.000490         0.5   \n",
       "14       0.002200  3.988753e-04         0.002000        0.001096         0.5   \n",
       "15       0.010199  1.490421e-02         0.002200        0.000981         0.7   \n",
       "16       0.003801  2.227022e-03         0.003600        0.003719         0.7   \n",
       "17       0.001801  7.494116e-04         0.001400        0.000489         0.7   \n",
       "18       0.002200  7.488537e-04         0.001200        0.000400         0.7   \n",
       "19       0.002000  6.345962e-04         0.001600        0.000799         0.7   \n",
       "20       0.002799  1.165591e-03         0.004200        0.002482         0.9   \n",
       "21       0.002000  6.327879e-04         0.001600        0.000489         0.9   \n",
       "22       0.002599  8.010870e-04         0.001200        0.000401         0.9   \n",
       "23       0.002001  6.333917e-04         0.001199        0.000399         0.9   \n",
       "24       0.001799  4.002581e-04         0.001200        0.000401         0.9   \n",
       "\n",
       "   param_l1_ratio param_max_iter  \\\n",
       "0             0.1          10000   \n",
       "1           0.325          10000   \n",
       "2            0.55          10000   \n",
       "3           0.775          10000   \n",
       "4             1.0          10000   \n",
       "5             0.1          10000   \n",
       "6           0.325          10000   \n",
       "7            0.55          10000   \n",
       "8           0.775          10000   \n",
       "9             1.0          10000   \n",
       "10            0.1          10000   \n",
       "11          0.325          10000   \n",
       "12           0.55          10000   \n",
       "13          0.775          10000   \n",
       "14            1.0          10000   \n",
       "15            0.1          10000   \n",
       "16          0.325          10000   \n",
       "17           0.55          10000   \n",
       "18          0.775          10000   \n",
       "19            1.0          10000   \n",
       "20            0.1          10000   \n",
       "21          0.325          10000   \n",
       "22           0.55          10000   \n",
       "23          0.775          10000   \n",
       "24            1.0          10000   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'alpha': 0.1, 'l1_ratio': 0.1, 'max_iter': 10...           0.666309   \n",
       "1   {'alpha': 0.1, 'l1_ratio': 0.325, 'max_iter': ...           0.667551   \n",
       "2   {'alpha': 0.1, 'l1_ratio': 0.55, 'max_iter': 1...           0.669260   \n",
       "3   {'alpha': 0.1, 'l1_ratio': 0.775, 'max_iter': ...           0.671644   \n",
       "4   {'alpha': 0.1, 'l1_ratio': 1.0, 'max_iter': 10...           0.675179   \n",
       "5   {'alpha': 0.3, 'l1_ratio': 0.1, 'max_iter': 10...           0.656540   \n",
       "6   {'alpha': 0.3, 'l1_ratio': 0.325, 'max_iter': ...           0.656440   \n",
       "7   {'alpha': 0.3, 'l1_ratio': 0.55, 'max_iter': 1...           0.656291   \n",
       "8   {'alpha': 0.3, 'l1_ratio': 0.775, 'max_iter': ...           0.656020   \n",
       "9   {'alpha': 0.3, 'l1_ratio': 1.0, 'max_iter': 10...           0.655297   \n",
       "10  {'alpha': 0.5, 'l1_ratio': 0.1, 'max_iter': 10...           0.652826   \n",
       "11  {'alpha': 0.5, 'l1_ratio': 0.325, 'max_iter': ...           0.651794   \n",
       "12  {'alpha': 0.5, 'l1_ratio': 0.55, 'max_iter': 1...           0.649989   \n",
       "13  {'alpha': 0.5, 'l1_ratio': 0.775, 'max_iter': ...           0.647124   \n",
       "14  {'alpha': 0.5, 'l1_ratio': 1.0, 'max_iter': 10...           0.647085   \n",
       "15  {'alpha': 0.7, 'l1_ratio': 0.1, 'max_iter': 10...           0.650658   \n",
       "16  {'alpha': 0.7, 'l1_ratio': 0.325, 'max_iter': ...           0.649046   \n",
       "17  {'alpha': 0.7, 'l1_ratio': 0.55, 'max_iter': 1...           0.646575   \n",
       "18  {'alpha': 0.7, 'l1_ratio': 0.775, 'max_iter': ...           0.646511   \n",
       "19  {'alpha': 0.7, 'l1_ratio': 1.0, 'max_iter': 10...           0.646448   \n",
       "20  {'alpha': 0.9, 'l1_ratio': 0.1, 'max_iter': 10...           0.649099   \n",
       "21  {'alpha': 0.9, 'l1_ratio': 0.325, 'max_iter': ...           0.647087   \n",
       "22  {'alpha': 0.9, 'l1_ratio': 0.55, 'max_iter': 1...           0.645932   \n",
       "23  {'alpha': 0.9, 'l1_ratio': 0.775, 'max_iter': ...           0.645834   \n",
       "24  {'alpha': 0.9, 'l1_ratio': 1.0, 'max_iter': 10...           0.645736   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.507689           0.626724           0.399908   \n",
       "1            0.506892           0.626705           0.400742   \n",
       "2            0.505688           0.626617           0.401880   \n",
       "3            0.503619           0.626260           0.403446   \n",
       "4            0.499566           0.625179           0.405727   \n",
       "5            0.510346           0.623985           0.393902   \n",
       "6            0.510236           0.624154           0.393951   \n",
       "7            0.510051           0.624387           0.394027   \n",
       "8            0.509632           0.624743           0.394168   \n",
       "9            0.507917           0.625298           0.394538   \n",
       "10           0.510875           0.621630           0.391732   \n",
       "11           0.510835           0.621616           0.391213   \n",
       "12           0.510792           0.621562           0.390288   \n",
       "13           0.510746           0.621382           0.388214   \n",
       "14           0.510687           0.620481           0.388018   \n",
       "15           0.511118           0.619597           0.390521   \n",
       "16           0.511064           0.619402           0.389654   \n",
       "17           0.510977           0.619017           0.388044   \n",
       "18           0.510740           0.618217           0.387901   \n",
       "19           0.510642           0.618249           0.387922   \n",
       "20           0.511244           0.617733           0.389666   \n",
       "21           0.511168           0.617373           0.388568   \n",
       "22           0.511007           0.616681           0.387689   \n",
       "23           0.510876           0.616524           0.387715   \n",
       "24           0.510825           0.616506           0.387742   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.587619         0.557650        0.094715                5  \n",
       "1            0.588331         0.558044        0.094851                4  \n",
       "2            0.589220         0.558533        0.095048                3  \n",
       "3            0.590253         0.559045        0.095345                2  \n",
       "4            0.591268         0.559384        0.095857                1  \n",
       "5            0.582869         0.553529        0.093575               10  \n",
       "6            0.583148         0.553586        0.093590                9  \n",
       "7            0.583580         0.553667        0.093611                8  \n",
       "8            0.584367         0.553786        0.093648                7  \n",
       "9            0.586316         0.553873        0.093745                6  \n",
       "10           0.581195         0.551652        0.092998               11  \n",
       "11           0.580934         0.551278        0.092938               12  \n",
       "12           0.580413         0.550609        0.092830               13  \n",
       "13           0.579151         0.549324        0.092835               17  \n",
       "14           0.577006         0.548655        0.092625               19  \n",
       "15           0.580403         0.550459        0.092568               14  \n",
       "16           0.579798         0.549793        0.092457               15  \n",
       "17           0.578553         0.548634        0.092356               20  \n",
       "18           0.577522         0.548178        0.092224               21  \n",
       "19           0.577626         0.548177        0.092223               22  \n",
       "20           0.579922         0.549533        0.092208               16  \n",
       "21           0.579099         0.548659        0.092056               18  \n",
       "22           0.577792         0.547820        0.091939               23  \n",
       "23           0.577966         0.547783        0.091906               25  \n",
       "24           0.578131         0.547788        0.091889               24  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mod = GridSearchCV(estimator=ElasticNet(),\n",
    "                   param_grid={\n",
    "                     'alpha': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "                     'l1_ratio': np.linspace(0.1,1,5),\n",
    "                     'max_iter':[10000]\n",
    "                   }, cv=5)\n",
    "\n",
    "mod.fit(X, y)\n",
    "pd.DataFrame(mod.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('planet4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a97243cb405ce325831496ff23b7ca76a6c0db2bb6c2ed99961e1c84fd8cf4ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
